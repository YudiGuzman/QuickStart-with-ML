{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dff74f9",
   "metadata": {},
   "source": [
    "# Eneisoft XIII - V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960a8d1",
   "metadata": {},
   "source": [
    "## Fase carga de datos limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7453d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65a64367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "15d1a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f2a26d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A1_cat</th>\n",
       "      <th>A4_cat</th>\n",
       "      <th>A5_cat</th>\n",
       "      <th>A6_cat</th>\n",
       "      <th>A7_cat</th>\n",
       "      <th>A9_cat</th>\n",
       "      <th>A10_cat</th>\n",
       "      <th>A12_cat</th>\n",
       "      <th>A13_cat</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  A1_cat  A4_cat  A5_cat  A6_cat  A7_cat  A9_cat  A10_cat  \\\n",
       "0           0       1       1       0      12       7       1        1   \n",
       "1           1       0       1       0      10       3       1        1   \n",
       "2           2       0       1       0      10       3       1        0   \n",
       "3           3       1       1       0      12       7       1        1   \n",
       "4           4       1       1       0      12       7       1        0   \n",
       "\n",
       "   A12_cat  A13_cat     A2     A3    A8  A11  A14  A15  A16  \n",
       "0        0        0  30.83  0.000  1.25    1  202    0    1  \n",
       "1        0        0  58.67  4.460  3.04    6   43  560    1  \n",
       "2        0        0  24.50  0.500  1.50    0  280  824    1  \n",
       "3        1        0  27.83  1.540  3.75    5  100    3    1  \n",
       "4        0        2  20.17  5.625  1.71    0  120    0    1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el conjunto de datos datalimpia guardado en la unidad anterior - 4\n",
    "filename = 'datalimpia_1.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14d80022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_cat</th>\n",
       "      <th>A4_cat</th>\n",
       "      <th>A5_cat</th>\n",
       "      <th>A6_cat</th>\n",
       "      <th>A7_cat</th>\n",
       "      <th>A9_cat</th>\n",
       "      <th>A10_cat</th>\n",
       "      <th>A12_cat</th>\n",
       "      <th>A13_cat</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>653 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_cat  A4_cat  A5_cat  A6_cat  A7_cat  A9_cat  A10_cat  A12_cat  \\\n",
       "0         1       1       0      12       7       1        1        0   \n",
       "1         0       1       0      10       3       1        1        0   \n",
       "2         0       1       0      10       3       1        0        0   \n",
       "3         1       1       0      12       7       1        1        1   \n",
       "4         1       1       0      12       7       1        0        0   \n",
       "..      ...     ...     ...     ...     ...     ...      ...      ...   \n",
       "648      -1       2       2       4       3       0        0        0   \n",
       "649       0       1       0       1       7       0        1        1   \n",
       "650       0       2       2       5       2       0        1        1   \n",
       "651       0       1       0       0       7       0        0        0   \n",
       "652       1       1       0       1       3       0        0        1   \n",
       "\n",
       "     A13_cat     A2      A3    A8  A11  A14  A15  A16  \n",
       "0          0  30.83   0.000  1.25    1  202    0    1  \n",
       "1          0  58.67   4.460  3.04    6   43  560    1  \n",
       "2          0  24.50   0.500  1.50    0  280  824    1  \n",
       "3          0  27.83   1.540  3.75    5  100    3    1  \n",
       "4          2  20.17   5.625  1.71    0  120    0    1  \n",
       "..       ...    ...     ...   ...  ...  ...  ...  ...  \n",
       "648        0  21.08  10.085  1.25    0  260    0    0  \n",
       "649        0  22.67   0.750  2.00    2  200  394    0  \n",
       "650        0  25.25  13.500  2.00    1  200    1    0  \n",
       "651        0  17.92   0.205  0.04    0  280  750    0  \n",
       "652        0  35.00   3.375  8.29    0    0    0    0  \n",
       "\n",
       "[653 rows x 16 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['Unnamed: 0']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e9051089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 16)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensiones de nuestro dataset limpio.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99089c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_cat</th>\n",
       "      <th>A4_cat</th>\n",
       "      <th>A5_cat</th>\n",
       "      <th>A6_cat</th>\n",
       "      <th>A7_cat</th>\n",
       "      <th>A9_cat</th>\n",
       "      <th>A10_cat</th>\n",
       "      <th>A12_cat</th>\n",
       "      <th>A13_cat</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.667688</td>\n",
       "      <td>1.229709</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>5.773354</td>\n",
       "      <td>5.084227</td>\n",
       "      <td>0.534456</td>\n",
       "      <td>0.439510</td>\n",
       "      <td>0.462481</td>\n",
       "      <td>0.165391</td>\n",
       "      <td>31.503813</td>\n",
       "      <td>4.829533</td>\n",
       "      <td>2.244296</td>\n",
       "      <td>2.502297</td>\n",
       "      <td>180.359877</td>\n",
       "      <td>1013.761103</td>\n",
       "      <td>0.453292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.502888</td>\n",
       "      <td>0.428193</td>\n",
       "      <td>0.845963</td>\n",
       "      <td>4.296249</td>\n",
       "      <td>2.494278</td>\n",
       "      <td>0.499194</td>\n",
       "      <td>0.496708</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.548475</td>\n",
       "      <td>11.838267</td>\n",
       "      <td>5.027077</td>\n",
       "      <td>3.371120</td>\n",
       "      <td>4.968497</td>\n",
       "      <td>168.296811</td>\n",
       "      <td>5253.278504</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.580000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.420000</td>\n",
       "      <td>2.835000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A1_cat      A4_cat      A5_cat      A6_cat      A7_cat      A9_cat  \\\n",
       "count  653.000000  653.000000  653.000000  653.000000  653.000000  653.000000   \n",
       "mean     0.667688    1.229709    0.468606    5.773354    5.084227    0.534456   \n",
       "std      0.502888    0.428193    0.845963    4.296249    2.494278    0.499194   \n",
       "min     -1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    0.000000    1.000000    3.000000    0.000000   \n",
       "50%      1.000000    1.000000    0.000000    6.000000    7.000000    1.000000   \n",
       "75%      1.000000    1.000000    0.000000   10.000000    7.000000    1.000000   \n",
       "max      1.000000    2.000000    2.000000   13.000000    8.000000    1.000000   \n",
       "\n",
       "          A10_cat     A12_cat     A13_cat          A2          A3          A8  \\\n",
       "count  653.000000  653.000000  653.000000  653.000000  653.000000  653.000000   \n",
       "mean     0.439510    0.462481    0.165391   31.503813    4.829533    2.244296   \n",
       "std      0.496708    0.498973    0.548475   11.838267    5.027077    3.371120   \n",
       "min      0.000000    0.000000    0.000000   13.750000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   22.580000    1.040000    0.165000   \n",
       "50%      0.000000    0.000000    0.000000   28.420000    2.835000    1.000000   \n",
       "75%      1.000000    1.000000    0.000000   38.250000    7.500000    2.625000   \n",
       "max      1.000000    1.000000    2.000000   76.750000   28.000000   28.500000   \n",
       "\n",
       "              A11          A14            A15         A16  \n",
       "count  653.000000   653.000000     653.000000  653.000000  \n",
       "mean     2.502297   180.359877    1013.761103    0.453292  \n",
       "std      4.968497   168.296811    5253.278504    0.498195  \n",
       "min      0.000000     0.000000       0.000000    0.000000  \n",
       "25%      0.000000    73.000000       0.000000    0.000000  \n",
       "50%      0.000000   160.000000       5.000000    0.000000  \n",
       "75%      3.000000   272.000000     400.000000    1.000000  \n",
       "max     67.000000  2000.000000  100000.000000    1.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd06ccf",
   "metadata": {},
   "source": [
    "## Fase de modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d2b81",
   "metadata": {},
   "source": [
    "### Creación del conjunto de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d5a9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando arrays a partir de los valores del dataset \"data\"\n",
    "array_clas = data.values\n",
    "X_clas = array_clas[ : , 0:15]\n",
    "Y_clas = array_clas[ : , 15]\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b647b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66131495, -0.53687283, -0.55435692, ..., -0.30259629,\n",
       "         0.12868165, -0.19312477],\n",
       "       [-1.32872498, -0.53687283, -0.55435692, ...,  0.70451573,\n",
       "        -0.81680202, -0.08644296],\n",
       "       [-1.32872498, -0.53687283, -0.55435692, ..., -0.50401869,\n",
       "         0.59250383, -0.0361501 ],\n",
       "       ...,\n",
       "       [-1.32872498,  1.80031354,  1.81162393, ..., -0.30259629,\n",
       "         0.11678877, -0.19293427],\n",
       "       [-1.32872498, -0.53687283, -0.55435692, ..., -0.50401869,\n",
       "         0.59250383, -0.05024734],\n",
       "       [ 0.66131495, -0.53687283, -0.55435692, ..., -0.50401869,\n",
       "        -1.07249886, -0.19312477]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escalamiento de datos\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_clas)\n",
    "scaler\n",
    "scaler.mean_\n",
    "scaler.scale_\n",
    "X_scaled = scaler.transform(X_clas)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "70f56e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_scaled, Y_clas, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb53010",
   "metadata": {},
   "source": [
    "### Algritmos Lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96435144",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f2ff5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.60% (4.52%)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression(solver= 'lbfgs', max_iter=5000)\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29de30",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7cd71d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.79% (4.12%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b8f7f",
   "metadata": {},
   "source": [
    "### Algoritmos No Lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c6866",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "74b97a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.49% (4.75%)\n"
     ]
    }
   ],
   "source": [
    "# KNN Classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kfold = KFold(n_splits=8, random_state=None)\n",
    "model = KNeighborsClassifier(n_neighbors=8, algorithm='kd_tree')\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956ba97",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87eaec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.89% (4.43)\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1c9bd",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16157336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.22% (5.36)\n"
     ]
    }
   ],
   "source": [
    "# CART Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = DecisionTreeClassifier(criterion= 'entropy')\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b385a",
   "metadata": {},
   "source": [
    "#### Super Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bad3c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.44% (5.71)\n"
     ]
    }
   ],
   "source": [
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d629e38",
   "metadata": {},
   "source": [
    "## Fase evaluación de los modelos lineales y no lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a6868b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LR']: 86.60% (4.52%)\n",
      "['LR', 'LDA']: 86.79% (4.12%)\n",
      "['LR', 'LDA', 'K-NN']: 84.48% (4.82%)\n",
      "['LR', 'LDA', 'K-NN', 'CART']: 81.22% (4.71%)\n",
      "['LR', 'LDA', 'K-NN', 'CART', 'NB']: 79.89% (4.43%)\n",
      "['LR', 'LDA', 'K-NN', 'CART', 'NB', 'SVM']: 85.44% (5.71%)\n"
     ]
    }
   ],
   "source": [
    "# Comparamos los algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver= 'lbfgs', max_iter=5000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('K-NN', KNeighborsClassifier(n_neighbors=8)))\n",
    "models.append(('CART', DecisionTreeClassifier(criterion= 'entropy')))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turnmodels = \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{names}: {cv_results.mean()*100.0:,.2f}% ({cv_results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ad80732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeOklEQVR4nO3dfbxcVX3v8c+XQEBihMQEKiEhCBEBH1CP+IhieQoo5UlrImpBbS5eaStahSJX48Or0ipFW2NzsZeLiBhoITVQJGh9UagP15xogCSAhBBNDGhCgIigEPjdP9Y6sDOZObPPyZk556x836/XeZ2ZWWvvvfbDfGfP2nv2VkRgZmbl2mm4G2BmZp3loDczK5yD3syscA56M7PCOejNzArnoDczK5yDfpSRdLqkm5q8PkPSbZL2G8JphaQDh2p8lfFOz+PeeajHnce/QtKRnRh3J3SrvZ1anyNNq/dIB6YzV9IVnZ7OUBj1QS/pXZJ6JT0q6X5J35H0xuFuV6dExDcj4tjqa5L2AL4GvD0ifjE8LduWpCNzuHy8m9ONiEMj4ubchhHxZuyvHdX2lixvC3dI2qny2uckXbYd49vmg6vZe2RHN6qDXtJHgC8BfwvsDUwDvgqcNIzNamuo92Qj4pGIODIi7hnK8Q6BPwM25f8d16lvCDak9gFmDXcjdjgRMSr/gD2AR4F39FNnV9IHwfr89yVg11x2JLAO+DjwG+B+4GTgBODnpIA6vzKuucC/AVcBvwV+Cry8Un4ecG8uWwmcUik7A/gBcHEe7+eAA4DvAw8CG4FvAntWhpkKXAtsyHW+UhnXf1fqvR5YAjyS/7++UnYz8Nk87d8CNwGT+lleH8vLYT3wPiCAAyvL8ovAL4FfA/OB5/Qzrt3zNGcBTwA9lbLpedw75+f7A7fk+t8D5gFXVOr/CbACeDjP08GVsjXAucDtwB+AnfNrRwMz87SfzNvKbZXl8jngh/n164Dn53WwOS/H6TWX8RnA6tz2+4DTWyyPudV5aihbAxxdqXc1cHke54qGZbcPcE3eLu4D/rJSdjjwo7yc7ge+AoytlNdan8Ak4Po8nk3ArcBOTdo9D7io4bXrgA+3mM/I6+qeyrr/HHBZnXXdYnwHNnn9DLZ+jwRwVp7uQ7ndqpS/D7gzly0G9quUfRlYm7eLpcARrdYp8Nq8TT0M3AYcOdDtpFN/wx7Yg254ehNv6dtgWtT5DPBjYC9gcl4Jn81lR+bhPwnsAvx5fvNcCYwHDgV+D7ywslKfBN6e6/91XmG75PJ3kN6EOwHvBH4HvKCykrcAf0EKoucABwLHkN5wk0lB96Vcf0zeUC4GxgG7AW9s3IiBiXnjfE8e7+z8/Pm5/GbSh8+L8jRvBi7sZ3n+GnhJnuaVbB0MXwIW5WmOJ72hP9/Psn8PKWzG5Lr/WCmbztZB/yNS6IwF3kh6U12Ry16Ul+Uxebl/HFhFDjBSSC4jfTA+p/JaNTivaGjbzXkcB5B2GFaSPtyPzsvxcuD/tlvGeTltBg7KdV8AHNpieWzTjkpZY3t/T9rhGAN8HvhxLtuJFDafzMvqhaTwOC6Xv4oUNjvnZXwnldCtuz7zNOfn5b0LcASVYKyM73DSTsFO+fkk4DFg7xbzGcCMPA8fyK89E/Tt1nWL8dUN+uuBPUnf+jcAM3PZyXkaB+fldgHww8qw787remfgo8ADwG6N6xSYQtohOyGvp2Py88kD2U46lpfdnNiQNhxOBx5oU+de4ITK8+OANfnxkcDjwJj8fHzeIF5Tqb8UOLmyUn9cKduJFGRHtJj2MuCkyob3yzZtPRn4WX78urwxbvMhxtZB/x7gJw3lPwLOyI9vBi6olP1P4MYW07+UyodAftMF6QNJ+Q14QKX8dcB9/czP93j2g2t2np++D8Xpedw75zfeFmD3yrBXVN5A/wu4umG5/4q8t0QKyfc1THsN7YP+E5XnFwHfqTw/EVjWbhmT3sAPA6fRz7ebVu3op73fq5QdAjyeH7+mcTsC/ob8odRkvB8GFlae11qfpB2kb9MkRJtM407gmPz4bOCGfur2Tf8E0jeJXdk66Ptd163G1997pFLvjZXnVwPn5cffAd7fMM3HqOzVN4z7IfI3ebYO+nOBbzTUXUzqtqy9nXTqbzT30T8ITGrTL7sPUD04+Yv82jPjiIin8uPH8/9fV8ofB55beb6270FEPE3q+tkHQNJ7JS2T9LCkh0l7xpOaDZvr7yVpgaRfSdpMCre++lOBX0TEln7mrdn89c3jlMrzByqPH2uYn8ZxVdtYHe9kUlfM0sr83Zhf34akqcBbSF0hkEJjN+CtLaa7KSIeq7y2tqH8mbbk5b6Wredxq2VbU+N6brXeWy7jiPgd6dvbWcD9kv5D0osH0ZZGjetst7yd7wfs07cO8no4n3R8CkkvknS9pAfyNvW3bL0N9mm3Pr9A2su9SdJqSef109avk/Z6yf+/0W7mIuIGUtDPaSiqs64Hq9X7YD/gy5XlsIn0QTgFQNJHJd0p6ZFcvgfNl+l+wDsa1s0bSd/qO7Wd1Daag/5HpK+4J/dTZz1pBfSZll8brKl9D/KZA/sC6/MpjV8j7dE8PyL2BJaTNpg+0TCuz+fXXhYRzyO9SfrqrwWm1Ti42Dh/kObxV3VnqOJ+KvOXx9NnIyn8Do2IPfPfHhHR6kPjPaRt6zpJD5C6F3YD3ttiuhMl7V55rdqOreZRknJ5dR4bly01y+rodxlHxOKIOIb0dfwu0nbQKWtJe917Vv7GR8QJufyfcxtm5G3qfLbeBvv0uz4j4rcR8dGIeCHp281HJB3Vok1XACdJejmp++Pfa87LBcAnSB84feqs66G2FvgfDcv0ORHxQ0lHkPbU/xSYkN/Xj9B8ma4l7dFXxzMuIi6Erm8n2xi1QR8Rj5D6KudJOlnS7pJ2kXS8pL/P1b4FXCBpsqRJuf72nGr3Kkmn5gD+MOng349JX82C1D2BpDNJe/T9GU86EPiwpCmkA6F9fkIKwAsljZO0m6Q3NBnHDcCL8immO0t6J+mr/vWDmLergTMkHZJD91N9BXnP6mvAxZL2yvM4RdJxLcb1XuDTwGGVv9OAt0p6frVipNNBe4G5ksZKeh0pXKrtequkoyTtQuon/QPpeEsdvwamV0/pG6CWy1jS3pL+RNK43KZHgaf6GddOeV32/e06wLb8BNgs6VxJz5E0RtJLJL06l48n9QU/mvcYP9hsJO3Wp6S3STowB+3mPE9N5ysi1pEOUH8DuCYiHm9Wr8lwNwN3sPUZWYNZ12MblumYOtOvmA/8jaRDIZ2qLOkduWw8qVtxA7CzpE8Cz2sxniuAEyUdl9fLbkqnF+87iO1kyI3aoAeIiH8APkLaO9hA+lQ9m2f3Kj5HCpHbSRvVT/Nrg/Vt0lewvoNzp0bEkxGxktTP+yNSsLyUdKZLfz4NvJK0h/AfpDNs+ubrKVLYHUj6irsuT3crEfEg8DbSG+JB0sGrt0XExoHOWER8h3SA7vukr+3fb6hybn79x7lb4HvAQY3jkfRaUh/8vIh4oPK3KA8/u8nkTyf1ET9IWj9Xkd4QRMTdpG87/0TaEz0RODEinqg5a/+a/z8o6ac1h3lGm2W8U359Pekr/5tJx0FamU3ak+77u3eAbenbLg4jnQiwEfgXUncCpBME3kU6s+NrpOXYSn/rc0Z+/ihpm/5q9H+e/9dJ23zbbpsGF5AOBgODXtcr2HqZnjmQBkTEQuDvgAV5OSwHjs/Fi0l9+D8ndSn9nhbdhBGxlnRa9/k8m0UfI20jA91OhpzyQQNrQ9Jc0oGfd7era9tH0lXAXRHxqbaVbdhJehNpj3Z6/rZgI8yo3qO3Mkh6taQDJO0kaSZpz+jfh7lZVkPuYvkr4F8c8iOXf0loI8Efkbqunk/qpvpgRPxseJtk7Ug6mNQ1ehsD7DKx7nLXjZlZ4dx1Y2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhal2PPt8M4svAGNINBi5sKJ8AXAocQLrd1vsiYnkuW0O6tdlTwJaI6Gk3vUmTJsX06dPrz4WZ2Q5u6dKlGyNicrOytkGfb7Y7DziGdFOIJZIW5fuk9jkfWBYRp+SbEs8DqneNf8tA7mM6ffp0ent761Y3M9vhSfpFq7I6XTeHA6siYnW+Se8C0q3eqg4B/hMgIu4Cpkvae5DtNTOzIVQn6Kew9Z3P1+XXqm4DTgWQdDiwH7BvLgvgJklLJc3ZvuaamdlA1emjV5PXGu8/eCHwZUnLgDuAnwFbctkbImK9pL2A70q6KyJu2WYi6UNgDsC0adNqNt/MzNqps0e/Dphaeb4vsL5aISI2R8SZEXEY8F5gMnBfLluf//8GWEjqCtpGRFwSET0R0TN5ctPjCWZmNgh1gn4JMEPS/pLGArOARdUKkvbMZQAfAG6JiM2Sxkkan+uMA44Flg9d883MrJ22XTcRsUXS2cBi0umVl0bECkln5fL5wMHA5ZKeAlYC78+D7w0slNQ3rSsj4sahnw0zM2tFEY3d7cOvp6cnfHqlmVl9kpa2+p2SfxlrZla4Wr+MLUHuPhqwkfiNx8xsIHaYoG8V2JIc5mZWNHfdmJkVzkFvZlY4B72ZWeEc9GZmhXPQm5kVzkFvZlY4B72ZWeEc9GZmhXPQm5kVzkFvZlY4B72ZWeEc9GZmhXPQm5kVzkFvZlY4B72ZWeF2mOvRl2ywN1WB0XFjldLnz0a30XBTIwd9AfrbYEq4sUrp82ej22i4qZG7bszMCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrXK2glzRT0t2SVkk6r0n5BEkLJd0u6SeSXlJ3WDOzkW7ixIlIGtAfMOBhJDFx4sQhb3/b69FLGgPMA44B1gFLJC2KiJWVaucDyyLiFEkvzvWPqjmsmdmI9tBDD3Xt2vLbc6OdVurs0R8OrIqI1RHxBLAAOKmhziHAfwJExF3AdEl71xzWzMw6qE7QTwHWVp6vy69V3QacCiDpcGA/YN+aw5KHmyOpV1Lvhg0b6rXezMzaqhP0zb5HNH6HuRCYIGkZ8BfAz4AtNYdNL0ZcEhE9EdEzefLkGs3asQymj3Ck9ROa2fCoc8/YdcDUyvN9gfXVChGxGTgTQCld7st/u7cb1urpZh8hdKaf0MyGR509+iXADEn7SxoLzAIWVStI2jOXAXwAuCWHf9thzcyss9ru0UfEFklnA4uBMcClEbFC0lm5fD5wMHC5pKeAlcD7+xu2M7NiZmbNqJvdAXX19PREb29vV6YlqatdIoPV7XZ6uZg9q5vb2WCnJWlpRPQ0K/MvY83MCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrXFFBP9ovJWpm1gl1LoEwaoz2S4mamXVCUXv0Zma2LQe9mVnhHPRmZoVz0JuZFc5BbyOCb6xi1jlFnXVjo5dvrGLWOd6jNzMrnIPezKxw7roZJeJTz4O5e3R3emYGdPf914n3XlF3mBoNd4Hx9HbM6dnoNhqyxXeYMjPbgTnozcwK56A3Myucg97MrHA+68ZsmG3Pj7d8QNnqcNCbDbP+wtpnB9lQKCroR/u5rmYl8jeW4VdU0OvTm7t7ruvcrkzKbFTzN5bh54OxZmaFc9CbmRXOQW9mVjgHvZlZ4Rz0ZmaFc9CbmRWuqNMrbfQq/Xr7EydO5KGHHhrUsIM5D33ChAls2rRpUNOz8jjobUTo5m8goPu/g/A9cW041eq6kTRT0t2SVkk6r0n5HpKuk3SbpBWSzqyUrZF0h6RlkgZ+NxEzM9subffoJY0B5gHHAOuAJZIWRcTKSrUPASsj4kRJk4G7JX0zIp7I5W+JiI1D3XgzM2uvzh794cCqiFidg3sBcFJDnQDGK31ffC6wCdgypC01M7NBqRP0U4C1lefr8mtVXwEOBtYDdwB/FRFP57IAbpK0VNKcVhORNEdSr6TeDRs21J4BMzPrX52gb3ZUp/Go0nHAMmAf4DDgK5L6Tmt4Q0S8Ejge+JCkNzWbSERcEhE9EdEzefLkOm03M7Ma6gT9OmBq5fm+pD33qjOBayNZBdwHvBggItbn/78BFpK6gszMrEvqBP0SYIak/SWNBWYBixrq/BI4CkDS3sBBwGpJ4ySNz6+PA44Flg9V483MrL22Z91ExBZJZwOLgTHApRGxQtJZuXw+8FngMkl3kLp6zo2IjZJeCCzM5/TuDFwZETd2aF7MzKyJWj+YiogbgBsaXptfebyetLfeONxq4OXb2UYzM9sOvtaNmVnhHPRmZoVz0JvZdps4cSKSBvwHDGq4iRMnDvMcjy6+qJmZbTdftG1k8x69mVnhHPRmZoUrruumW1/pJkyY0JXpmJltr6KCfjB9hJK62rdoZtZt7roxMyucg97MrHBFdd2UrpunlPkYhFk5HPSjxGCPI/gYhJm568bMrHAOejOzwjnozcwK56A3Myucg97MrHAOejOzwjnozcwK56A3Myucg97MrHAOejOzwvkSCGZdEJ96Hszdo7vTM8sc9GZdoE9v7vo9VWNu1yZnI5yD3kYMX53TrDMc9DYi+OqcZp3jg7FmZoVz0JuZFc5Bb2ZWOAe9mVnhfDDWzKyGbp0V1okzwhz0BWi3AfZX7jNWzNobzPtkJJ0R5qAvwEjZmMxsZHIfvZlZ4WoFvaSZku6WtErSeU3K95B0naTbJK2QdGbdYc3MrLPaBr2kMcA84HjgEGC2pEMaqn0IWBkRLweOBC6SNLbmsGZm1kF19ugPB1ZFxOqIeAJYAJzUUCeA8UpH/Z4LbAK21BzWzMw6qM7B2CnA2srzdcBrGup8BVgErAfGA++MiKcl1RkWAElzgDkA06ZNq9V4MxsZfBnmka1O0Dc7N6/xNI/jgGXAHwMHAN+VdGvNYdOLEZcAlwD09PT4NBKzUcSXYR7Z6nTdrAOmVp7vS9pzrzoTuDaSVcB9wItrDmtmZh1UJ+iXADMk7S9pLDCL1E1T9UvgKABJewMHAatrDmtmZh3UtusmIrZIOhtYDIwBLo2IFZLOyuXzgc8Cl0m6g9Rdc25EbARoNmxnZsXMzJrRSPxVZU9PT/T29nZlWiPpZ8o2cKNl/XW7nZ7e8BuGZbI0InqalfmXsWZmhXPQm5kVzkFvZlY4X73SrEu6dT1z6Mw1zW302mGCvr83ma/Xbp022O1oNBx0tJFvhwl6v1nMbEflPnozs8I56M3MCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrnIPezKxwDnozs8I56M3MCuegNzMrnIPezKxwDnozs8I56M3MCrfDXKbYRq92N+zw/QTM+uegtxHPYW22fdx1Y2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc4/mDKzIdHuF8xDacKECV2bVgkc9Ga23Qb762VJ/uVzF7jrxsyscA56M7PC1Qp6STMl3S1plaTzmpR/TNKy/Ldc0lOSJuayNZLuyGW9Qz0DZmbWv7Z99JLGAPOAY4B1wBJJiyJiZV+diPgC8IVc/0TgnIjYVBnNWyJi45C23MzMaqmzR384sCoiVkfEE8AC4KR+6s8GvjUUjTMzs+1XJ+inAGsrz9fl17YhaXdgJnBN5eUAbpK0VNKcVhORNEdSr6TeDRs21GiWmdnwk9T0r7+ybp6KCvVOr2zWolbnQ50I/KCh2+YNEbFe0l7AdyXdFRG3bDPCiEuASwB6enp8vpWZjQqj4fTQOnv064Cplef7Autb1J1FQ7dNRKzP/38DLCR1BZmZWZfUCfolwAxJ+0saSwrzRY2VJO0BvBn4duW1cZLG9z0GjgWWD0XDzcysnrZdNxGxRdLZwGJgDHBpRKyQdFYun5+rngLcFBG/qwy+N7Aw90ftDFwZETcO5QyYmVn/NBL7l3p6eqK316fcm5V+iYDS56+bJC2NiJ5mZf5lrJlZ4Rz0ZmaFc9CbmRXOQW9mVjgHvZlZ4Rz0ZmaFc9CbmRXOQW9mVjgHvZlZ4Rz0ZmaFq3OZYjOzQWt37fX+yn15hKHhoDezjnJYDz933ZiZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhHPRmZoVz0JuZFc5Bb2ZWOAe9mVnhfD16s2HmG3NYpznozYaZw9o6zV03ZmaFc9CbmRXOQW9mVjgHvZlZ4WoFvaSZku6WtErSeU3KPyZpWf5bLukpSRPrDGtmZp3VNugljQHmAccDhwCzJR1SrRMRX4iIwyLiMOBvgP+KiE11hjUzs86qs0d/OLAqIlZHxBPAAuCkfurPBr41yGHNzGyI1Qn6KcDayvN1+bVtSNodmAlcM9BhzcysM+r8YKrZz/Ja/cLjROAHEbFpoMNKmgPMyU8flXR3jbYNhUnAxi5Nazh4/kY3z9/o1e15269VQZ2gXwdMrTzfF1jfou4snu22GdCwEXEJcEmN9gwpSb0R0dPt6XaL52908/yNXiNp3up03SwBZkjaX9JYUpgvaqwkaQ/gzcC3BzqsmZl1Tts9+ojYIulsYDEwBrg0IlZIOiuXz89VTwFuiojftRt2qGfCzMxaq3VRs4i4Abih4bX5Dc8vAy6rM+wI0/Xuoi7z/I1unr/Ra8TMm3zlPDOzsvkSCGZmhduhgl7So01emyvpV/nyDSslzR6Otg1Gjfm5R9K1jb9GlvQKSSHpuO61tr7qfEk6Ic/HtIY6ayRdU3n+dkmX5cdnSHpa0ssq5cslTe986/sn6Y8kLZB0b97ebpD0olx2jqTf5xMb+uofKekRST+TdJekL0p6aeWSI5sk3Zcff2/45qy1vK1dVHn+15Lm5sfV7fUuSf8sacTnkqRPSFoh6fbc9u9I+nxDncMk3Zkfr5F0a0P5MknLu9HeEb9Au+TifPmGk4D/LWmXYW7P9ro4X5JiBnAV8H1Jkyvls4H/zv9HLElHAf8EzIyIXzap0iPp0BaDrwM+0bHGDYLSraIWAjdHxAERcQhwPrB3rjKbdKbaKQ2D3hoRrwBeAbwNeF7lkiOLgI/l50d3Yz4G4Q/AqZImtSjve/8dAryUdPbeiCXpdaT18MqIeBlwNHAh8M6GqrOAKyvPx0uamsdxcDfa2sdBXxER9wCPAROGuy1DJSKuAm4C3gXPhM3bgTOAYyXtNnyta03SEcDXgLdGxL0tqn2RFJTNXA8cKumgTrRvkN4CPFk9kSEilkXErZIOAJ4LXECLD+CIeBxYxuj7dfkW0oHJc9rUGwvsBjzU8RZtnxcAGyPiDwARsTEi/gt4WNJrKvX+lHTZlz5X8+yHQfVSMR3noK+Q9Ergnoj4zXC3ZYj9FHhxfvwG4L4cnjcDJwxXo/qxK+n3GCdHxF391LsaeKWkA5uUPQ38Pa0/CIbDS4ClLcr63vi3AgdJ2quxgqQJwAzglo61sHPmAadXu6UqzpG0DLgf+HlELOtmwwbhJmCqpJ9L+qqkvm8g3yLtxSPptcCDeeexz78Bp+bHJwLXdavBDvrknHzJhf8HzB3mtnRC9VIUs3l2L2MBI7P75kngh8D729R7CvgC6YqpzVwJvFbS/kPYtk6ZBSyIiKeBa4F3VMqOkHQ78ABwfUQ8MBwN3B4RsRm4HPjLJsV9XTd7AeMkzepm2wYqIh4FXkW6ZMsG4CpJZ5DeT2/PxxgarxIAsAl4KM/fnaTeg65w0CcXR8RBpK9Vl4/U7ozt8ArgTqXLRp8GfFLSGlL/9/GSxg9n45p4mvS199WSzpc0pnLw8TMNdb8BvAmY1jiSiNgCXASc2/EW17OCFBBbyQeNZwDfzetlFlt/AN+a+4JfCnxQ0mGdb2pHfIn04T2uWWFEPAncSFqfI1pEPBURN0fEp4CzgdMiYi2whnSM4TTSN85GV5G+3XSt2wYc9FuJiGuBXuDPhrstQ0XSacCxpA3raOC2iJgaEdMjYj/SlUZPHsYmNhURj5EOeJ0OnNF38DEiPtlQ70ngYuDDLUZ1GWm+J7co76bvA7tK+vO+FyS9GvgyMDevk+kRsQ8wRdJWF6mKiJ8Dn2fkfHANSL7Y4dW0+KaWjx+9Hmh1TGZEkHSQpBmVlw4DfpEff4u0Pd4bEeuaDL6Q1KW4uKONbLCjBf3uktZV/j7SpM5ngI+MhlO8aD0/5+S933uAdwN/HBEbSHuJCxvGcQ35QO1Ik4NhJnCBpP7uY/B/aPEr73wfhH8kdQsMq0i/TjwFOCafXrmC1FV4JNuul4Xk/t4G84E3jZLuqGYuIl3Vsaqvj345aT1+tduNGqDnAl/Pp8feTjpbaG4u+1fgULY+CPuMiPhtRPxd3i67xr+MNTMr3GjYazUzs+3goDczK5yD3syscA56M7PCOejNzArnoDczK5yD3syscA56M7PC/X8tqUBux7Z9XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig=plt.figure()\n",
    "fig.suptitle('Comparación de Algoritmos Lineales y No Lineales')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975fa571",
   "metadata": {},
   "source": [
    "Los resultados sugieren profundizar en los algoritmos LDA y  LR. Es muy probable que una configuración más allá de la predeterminada pueda generar modelos con mejor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a953271",
   "metadata": {},
   "source": [
    "## Fase optimización de los mejores modelos lineales y no lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b44f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.40% (4.22%)\n"
     ]
    }
   ],
   "source": [
    "#Se seteo los parámetros con los valores asignados por compatibilidad entre los parámetros 'solver' y 'shrinkage'\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b7c25",
   "metadata": {},
   "source": [
    "El proceso de optimización de un modelo algorítmico requiere una investigación profunda de los parámetros/hiperparámetros con los que trabaja cada modelo por lo que no siempre se obtiene los resultados esperados. En este caso, sin la optimización del modelo LDA se obtuvo 86.79% de acierto respecto a 86.40% con optimización. Por lo que el impacto ha sido insignificante en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a143fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.41% (4.21%)\n"
     ]
    }
   ],
   "source": [
    "#Se seteo los parámetros con los valores asignados por compatibilidad entre los parámetros 'penalty' y 'solver'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = LogisticRegression(penalty='l1',solver= 'liblinear', max_iter=1000)\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcaa2e",
   "metadata": {},
   "source": [
    "En este caso, se observa que la optimización del modelo LR sin la optimización del modelo obtuvo 86.60% de acierto respecto a 86.41% con optimización. Por lo que el impacto ha sido insignificante en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222325f",
   "metadata": {},
   "source": [
    "### Algoritmos de conjuntos o ensamblados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0c732",
   "metadata": {},
   "source": [
    "Otra forma en que podemos mejorar el rendimiento de los algoritmos en este problema es mediante el uso de modelos ensamblados. En esta sección evaluaremos cuatro algoritmos ensamblados diferentes, dos tipo Boosting y dos tipo  Bagging:\n",
    "* Métodos Boosting: AdaBoost (AB) y Gradient Boosting (GBM).\n",
    "* Métodos Bagging: Random Forest (RF) y Extra Trees (ET).\n",
    "\n",
    "Utilizaresmo una validación cruzada de 10. No se utiliza la estandarización de datos en este caso porque los cuatro algoritmos de conjunto se basan en árboles de decisión que son menos sensibles a las distribuciones de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "72029afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6c4fa2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 85.63% (4.86%)\n",
      "GBM: 86.01% (5.03%)\n",
      "RF: 88.31% (6.11%)\n",
      "ET: 87.74% (5.10%)\n"
     ]
    }
   ],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "ensembles.append(('RF', RandomForestClassifier()))\n",
    "ensembles.append(('ET', ExtraTreesClassifier()))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean()*100.0:,.2f}% ({cv_results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f42abacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparamos los algoritmos de conjunto\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparación de algoritmos de ensamblado')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684dd32b",
   "metadata": {},
   "source": [
    "Los resultados sugieren que RF y ET puede ser digno de una mayor investigación con una media fuerte y una extensión que se inclina al 90% de Accuracy.,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa5547",
   "metadata": {},
   "source": [
    "## Fase optimización de los mejores modelos ensamblados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c17ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.31% (5.54%)\n"
     ]
    }
   ],
   "source": [
    "#Se seteo bootstrap en True para que no considere todo el dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = RandomForestClassifier(bootstrap=True)\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d28a92",
   "metadata": {},
   "source": [
    "En este caso, se observa que la optimización del modelo RF mantuvo el mismo porcentaje de acierto que el modelo sin optimización por lo que podría seguir investigando para complejizar un poco el modelo a fin de obtener un mejor Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f977c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.94% (4.93%)\n"
     ]
    }
   ],
   "source": [
    "#El parámetros 'exponential' se usó para aplicar el efecto del algoritmo AdaBoost en lugar de LR si se por default. Learning_rate contribuye en el aprendizaje de los valores calculados para generar el siguiente árbol.\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "model = ExtraTreesClassifier(criterion='log_loss', max_features='log2', bootstrap=True, oob_score=False)\n",
    "results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "print(f'Accuracy: {results.mean()*100.0:,.2f}% ({results.std()*100.0:,.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a039df",
   "metadata": {},
   "source": [
    "En este caso, se observa que la optimización del modelo ET obtuvo una ligera mejora en el porcentaje de acierto de la clase target. Obteniendo 87.94% frente a 87.74% que se obtuvo antes de realizar el tuneo del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafdae9",
   "metadata": {},
   "source": [
    "## Fase de Forecasting o Fase de Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff66334",
   "metadata": {},
   "source": [
    "El RF mostró el mejor resultado (88.31%) como un modelo estable y de baja complejidad. En esta sección finalizaremos el modelo entrenándolo en todo el conjunto de datos de entrenamiento y haremos predicciones para el conjunto de datos de validación para confirmar nuestros hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2712c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687\n",
      "[[71  9]\n",
      " [10 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88        80\n",
      "         1.0       0.82      0.80      0.81        51\n",
      "\n",
      "    accuracy                           0.85       131\n",
      "   macro avg       0.85      0.85      0.85       131\n",
      "weighted avg       0.85      0.85      0.85       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare aand Finalize Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(rescaledX, Y_train)\n",
    "\n",
    "# estimate accuracy on validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b5219",
   "metadata": {},
   "source": [
    "Podemos ver que alcanzamos una precisión de 85% en el conjunto de datos de validación. Un porcentaje de acierto significativamente balanceado considerando que el Accuracy logrado durante el entrenamiento + optimización del modelo alcanzó 87.94% con lo cual se demuestra que se ha validado correctamente el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796e68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
